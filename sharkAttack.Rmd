---
output:
  pdf_document: default
  html_document: default
---
 ---
title: "36-402 Final Project"
author: "Darin Chaoui Jett Hays Emily Huang"
date: "4-12-23"
output: pdf_document
---


```{r}
# load data
sharkTank = read.csv("sharkTank.csv", header=TRUE)
```

```{r, message=FALSE}
# load required packages
library(np)
library(mgcv)
library(ggplot2)
library(tidyr)
```

## Intro
Shark tank is a popular business reality show. The show features a panel of wealthy investors who listen to pitches from aspiring entrepreneurs. 

Since launching in 2009, Shark Tank has become popular for its high-stakes negotiations and dramatic moments, as well as its inspirational stories of entrepreneurs who have turned their dreams into successful businesses. This paper focuses on describing the relationship between companies and investment.

Our dataset includes the quantitative variables mix of categorical askedfor, exchangeForStake, and valuation. These variables measure the requests made by a given company. We also consider a range of categorical variables including company description, location, and episode. 
Overall, we found that the requested valuation trends upward with season and that category is associated with deal flow. We also found that the amount asked for is negatively associated with the likelihood of obtaining a deal. We believe these insights will help entrepreneurs structure better pitches and help entrepreneurs recognize patterns in their own behavior. 

## Shark Preferences.
We want to know whether or not each shark has a preference on category of company. 

```{r}
# subset dataset with only the sharks, category, and deal or no deal
sharkCat = sharkTank[, c("shark1", "shark2", "shark3", "shark4", "shark5", "category", "deal")]
sharkCat <- sharkCat %>%
  pivot_longer(cols = starts_with("shark"), names_to = "shark", 
               values_to = "name")
sharkCat = subset(sharkCat, select = -shark)
```

```{r}
# combine categories into broader categories
broaderCats = list(Novelties = c("Novelties"), 
                   Food = c("Specialty Food"), 
                   Family = c("Baby and Child Care", 
                              "Baby and Children's Entertainment", 
                              "Maternity", "Weddings", 
                              "Baby and Children's Apparel and Accessories", 
                              "Baby and Children's Bedding", 
                              "Baby and Children's Food"),
                   OnlineandConsumerServices = c("Consumer Services"),
                   ApparelandAccessories = c("Men and Women's Apparel", 
                                             "Women's Accessories", 
                                             "Undergarments and Basics", 
                                             "Fashion Accessories", 
                                             "Women's Apparel", "Women's Shoes", 
                                             "Men's Accessories", 
                                             "Men and Women's Shoes", 
                                             "Men and Women's Accessories", 
                                             "Costumes"),
                   Education = c("Productivity Tools", "Education"),
                   ElectronicsandAutomotive = c("Automotive", "Electronics", 
                                                "Mobile Apps"),
                   GardeningandHomeImprovement = c("Kitchen Tools", "Gardening", 
                                                   "Furniture", 
                                                   "Storage and Cleaning Products", 
                                                   "Home Improvement", 
                                                   "Home Accessories", 
                                                   "Pest Control", 
                                                   "Home Security Solutions"),
                   Entertainment = c("Music", "Entertainment", "Toys and Games", 
                                     "Holiday Cheer", "Party Supplies"),
                   OnlineandConsumerServices = c("Professional Services", 
                                                 "Online Services"),
                   FitnessandSports = c("Fitness Equipment", "Fitness Programs", 
                                        "Golf Products", "Outdoor Recreation", 
                                        "Fitness Apparel and Accessories", 
                                        "Cycling"),
                   Beverages = c("Non-Alcoholic Beverages", 
                                 "Alcoholic Beverages", "Water Bottles", 
                                 "Wine Accessories"),
                   PetProducts = c("Pet Products"),
                   HealthandPersonalCare = c("Personal Care and Cosmetics", 
                                             "Health and Well-Being", 
                                             "Homeopathic Remedies"))

vec = vector("character", nrow(sharkCat))
for (i in 1:nrow(sharkCat)) {
  for (j in 1:length(broaderCats)) {
    if (sharkCat$category[i] %in% broaderCats[[j]]) {
      vec[i] = names(broaderCats)[j]
    }
  }
}
sharkCat$broaderCategory = vec
```

```{r}
chisq.test(table(sharkCat$broaderCategory, sharkCat$deal))
```

Since we get a p-value less than the alpha of 0.05, we conclude that there is a statistically significant association between the category and deal.

```{r}
# plot the shark name vs. broader category
sharkCat %>%
  ggplot(aes(x = broaderCategory, y = name, color = deal)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 5)) +
  labs(x = "Category", y = "Shark Name", 
       title = "Category vs. Sharks by Deal or No Deal")
```

This plot shows that all companies with the broader categories of Beverages, Electronics and Automotive, and Gardening and Home Improvement are always approved by every Shark. However, each Shark tends to only accept deals in certain broader categories such as Family or Food. So, companies with categories of Beverages, Electronics and Automotive, and Gardening and Home Improvement have a higher likelihood of getting a deal.

## The relationship between episode number (show progression) and the valuation of companies

```{r}
sharkVal = sharkTank[, c("season", "valuation")]
sharkVal %>%
  ggplot(aes(x = season, y = valuation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  scale_y_continuous(labels = scales::dollar_format(prefix = "$")) +
  labs(title = "Mean Valuation by Season", x = "Season", y = "Mean Valuation (USD)") +
  theme_minimal()
```

This barchart shows that as the seasons progress, the valuation of each company increases significantly. There could be several reasons why the valuation of companies has increased as the seasons progress in addition to external factors such as changes in the market or overall economic conditions. The first possibility could be exposure since as the show gains more popularity and viewership, the exposure for companies on the show increases. This means that more people are becoming aware of the companies and their products, leading to increased interest and demand. The second possibility could be investor confident since  investors may become more confident in their ability to identify successful companies and products. This could lead to higher valuations for the companies, as investors are more willing to take risks and invest larger amounts of money. The last possibility could be show format since the show itself could also play a role in increasing valuations as the seasons progress. For example, as the show gains popularity, it may attract more successful entrepreneurs and companies, leading to a higher quality of pitches and products. This could in turn lead to higher valuations, as the companies on the show are more likely to be successful.


## Predicting Shark Tank Success
We are also interested in predicting the success of shark tank applicants. A better understanding of what factors influence investor decisions can help founders create better pitches. 


```{r}
# create separate df to avoid conflict w/ other sections
sharkTank2 = sharkTank
# code deal as 1/0
sharkTank2$success = as.integer(as.logical(sharkTank2$deal))
# factorize categorical predictors
sharkTank2$category = as.factor(sharkTank2$category)
sharkTank2$multiple_entreprenuers = as.factor(as.logical(sharkTank2$multiple_entreprenuers))
# sharkTank2$episode = as.factor(sharkTank$episode)
# create transformed predictors
sharkTank2$descriptionLen = nchar(sharkTank$description)
sharkTank2$websiteLen = nchar(sharkTank$website)
sharkTank2$titleLen = nchar(sharkTank$title)
```

Our response of interest is pitch 'success'. A pitch is considered successful if the founders earned a deal (denoted as 1). The table below indicates that more pitches are successful than unsuccessful. This may reflect selection bias, with show creators more likely to broadcast high quality pitches. Regardless, the difference is small and does not cause concern about class imbalance. 

```{r}
# table 
dealTable = table(sharkTank2$success)
# rename table columns
rownames(dealTable) = c("Failure", "Success")
dealTable
```

We use logistic regression to model the relationship between deal success and predictors. Our first model will include 'product category' and whether or not a company had multiple founders as categorical predictors. In addition we include the following quantitative predictors: description length, title length, website length, valuation, exchange for stake, and amount asked for.

```{r}
# fit full model
sharkModFull = glm(success ~ category + multiple_entreprenuers + descriptionLen + websiteLen + titleLen + valuation + askedfor + exchangeforstake,
data = sharkTank2, family = binomial)
```

The full model achieves an AIC (an estimator of prediction error) of 728. In adition, we notice that only 'askedFor' and 'descriptionLen' were considered 'significant', with coefficient p-values below the standard .o5 significance threshold. 

Next, we run backwards elimination to find a reduced model that minimizes AIC. 

```{r}
sharkModOpt = step(sharkModFull, direction = "backward", trace = 0)
```


```{r}
sharkModTest = anova(sharkModFull, sharkModOpt, test="Chisq")
sharkModTest
sharkModTestStat=sharkModTest$Deviance[2]
```

Our reduced model only includes description length, valuation, and exchange for stake as predictors. The model achieves an AIC of 675 hich is lower than our full model. To determine whether or not, the full model is justified, we run a deviance analysis test. Our null hypothesis is that the full model does not have a significant increase in predictive power. After running our test, we obtain a p-value of .3259, which falls outside of .05 significance threshold. 

The calibration curve of our logistic regression is shown below, with the ideal response shown as a diagonal line from 0 to 1. This corresponds to the case when the fraction of successes is equivalent to our estimated rate of occurrence. Looking at the chart, we can see that the fraction of successes is noticeably higher than our predicted rate for estimated probabilities of .25 and .9. This indicates we are underestimating the amount of successes at these probability levels. 

```{r}
# plot calibration curve

probs <- seq(0.05, 0.95, by = 0.1)
estRates <- numeric(10)
for (i in seq_along(probs)) {
lower_bound <- probs[i] - 0.05
upper_bound <- probs[i] + 0.05
estRates[i] <- mean(sharkTank2$success[fitted(sharkModOpt) > lower_bound &
fitted(sharkModOpt) <= upper_bound])
}



tempCalibrationDf = data.frame(probs=probs, estRates=estRates)


ggplot(tempCalibrationDf, aes(x=probs, y=estRates)) + xlab("Estimated P(Y = 1 | X)")+ylab("Fraction of cases with Y = 1")+
  geom_point(size=2, shape=23, fill="blue")+labs(title="Logistic Regression Calibration Curve", caption = "The calibration plot shows the comparative fraction of positive cases against the predicted probability.")+geom_abline(intercept = 0, slope = 1, color="green")
```

Since the reduced model is simpler and achieves better predictive performance than the full model, we will proceed with the reduced model. Analyzing the model coefficients, we can see that valuation is associated with almost no difference in the odds of getting a deal. We also notice that every one percent increase in exchange for stake is associated with a multiplication of the odds of deal success by ~.977. This means that requests for higher percentage of the company are associated with a decrease in the odds of getting a deal. The confusion matrix of predictions is shown below. 

```{r}
# compute classification accuracy
n <- nrow(sharkTank2)
# fitted vals
p <- fitted(sharkModOpt)
names(p) <- NULL
# .05 threshold 
sharkPreds <- ifelse(p > 0.5, 1, 0)
# confusion matrix
sharkPredTable = table(sharkTank2$success, sharkPreds)
names(dimnames(sharkPredTable)) <- c("Observed", "Predicted")
# in-sample error rate (i.e. training error rate )
error = sum(sharkTank2$success != sharkPreds) / n
# interpreted coefficients
interpSharkCoef = exp(coef(sharkModOpt))
```

```{r}
# visualize confusion matrix
sharkPredDf = data.frame(sharkPredTable)
ggplot(data =  sharkPredDf, mapping = aes(x = Observed, y = Predicted)) +
  geom_tile(aes(fill = Freq), colour = "white") +
  geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
  scale_fill_gradient(low = "red", high = "green") +
  theme_bw() + theme(legend.position = "none")+labs(title="Reduced Model Confusion Matrix", caption = "The confusion matrix for our reduced logistic regression model. True positives and true negatives are shown in shades of green.")
```

The confusion matrix indicates our model produces more false positives than false negatives at a .5 classification threshold. Overall, the in sample classification accuracy of our reduced model is ~.6. 

```{r}
# load partial response library
library(pdp)
```



## Conclusion 
 
